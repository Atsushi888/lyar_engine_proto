# judge_ai.py â€” ãƒãƒ«ãƒAIå¯©è­°ç”¨ã‚¸ãƒ£ãƒƒã‚¸ã‚¯ãƒ©ã‚¹

from __future__ import annotations

from typing import Any, Dict, Optional, Tuple
import json

from llm_router import call_with_fallback


class JudgeAI:
    """
    è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®å¿œç­”ã‚’æ¯”è¼ƒã—ã¦ã€Œã©ã¡ã‚‰ãŒã‚ˆã‚Šè‰¯ã„ã‹ã€ã‚’åˆ¤å®šã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚

    è²¬å‹™:
        - llm_meta["models"] ã‹ã‚‰æ¯”è¼ƒå¯¾è±¡ãƒ¢ãƒ‡ãƒ«ã‚’é¸ã¶
        - LLM ã«è©•ä¾¡ã‚’ä¾é ¼ã™ã‚‹
        - winner / score_diff / comment ã‚’å«ã‚€ dict ã‚’è¿”ã™
        - å¿…è¦ã§ã‚ã‚Œã° llm_meta["judge"] ã«çµæœã‚’æ›¸ãè¾¼ã‚€

    UIï¼ˆStreamlit ç­‰ï¼‰ã«ã¯ä¸€åˆ‡ä¾å­˜ã—ã¾ã›ã‚“ã€‚
    """

    def __init__(self) -> None:
        # å°†æ¥çš„ã«ã€Œå¯©åˆ¤å°‚ç”¨ãƒ¢ãƒ‡ãƒ«ã€ã‚’åˆ‡ã‚Šæ›¿ãˆãŸããªã£ãŸå ´åˆã€
        # ã“ã“ã«è¨­å®šã‚’å¢—ã‚„ã™ä½™åœ°ã‚’æ®‹ã—ã¦ãŠãã¾ã™ã€‚
        pass

    def run(self, llm_meta: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        llm_meta ã‚’å—ã‘å–ã‚Šã€models ã‹ã‚‰ 2 ã¤ã‚’é¸ã‚“ã§å¯©è­°ã‚’è¡Œã„ã¾ã™ã€‚

        - models ãŒ 2 ã¤æœªæº€ã®å ´åˆã¯ None ã‚’è¿”ã—ã¾ã™
        - æˆåŠŸæ™‚ã¯ judge dict ã‚’è¿”ã—ã€llm_meta["judge"] ã«ã‚‚åŒã˜ã‚‚ã®ã‚’æ ¼ç´ã—ã¾ã™
        """
        if not isinstance(llm_meta, dict):
            return None

        models = llm_meta.get("models")
        if not isinstance(models, dict) or len(models) < 2:
            return None

        a_key, b_key = self._choose_pair(models)

        prompt = llm_meta.get("prompt_preview") or ""
        reply_a = str(models[a_key].get("reply") or models[a_key].get("text") or "")
        reply_b = str(models[b_key].get("reply") or models[b_key].get("text") or "")

        judge = self._evaluate_pair(
            prompt=prompt,
            reply_a=reply_a,
            reply_b=reply_b,
            label_a=a_key,
            label_b=b_key,
        )

        llm_meta["judge"] = judge
        return judge

    def _choose_pair(self, models: Dict[str, Any]) -> Tuple[str, str]:
        """
        æ¯”è¼ƒå¯¾è±¡ã¨ã™ã‚‹ 2 ãƒ¢ãƒ‡ãƒ«ã®ã‚­ãƒ¼ã‚’é¸ã³ã¾ã™ã€‚

        å„ªå…ˆé †ä½:
            1. "gpt4o" ã¨ "hermes" ã®çµ„ã¿åˆã‚ã›ãŒä¸¡æ–¹ã‚ã‚Œã°å›ºå®šã§ãã‚Œã‚’ä½¿ã†
            2. ãã†ã§ãªã‘ã‚Œã° models ã®å…ˆé ­ 2 ä»¶
        """
        if "gpt4o" in models and "hermes" in models:
            return "gpt4o", "hermes"

        keys = list(models.keys())
        if len(keys) >= 2:
            return keys[0], keys[1]

        # ã“ã“ã«æ¥ã‚‹ã®ã¯ len(models) < 2 ã®ã¨ãã ã‘ã§ã™ãŒã€
        # å‹å®‰å…¨ã®ãŸã‚ä¸€å¿œåŒã˜ã‚­ãƒ¼ã‚’è¿”ã—ã¦ãŠãã¾ã™ã€‚
        return keys[0], keys[0]

    def _evaluate_pair(
        self,
        prompt: str,
        reply_a: str,
        reply_b: str,
        label_a: str,
        label_b: str,
    ) -> Dict[str, Any]:
        """
        å®Ÿéš›ã« LLM ã« A/B æ¯”è¼ƒã‚’ä¾é ¼ã—ã€åˆ¤å®šçµæœã‚’ dict ã§è¿”ã—ã¾ã™ã€‚

        æˆ»ã‚Šå€¤ã®ä¾‹:
            {
                "winner": "gpt4o",
                "score_diff": 0.6,
                "comment": "...",
                "raw_json": {...}  # è§£ææ¸ˆã¿JSON
                "raw_text": "...",  # LLMã®ç”Ÿãƒ†ã‚­ã‚¹ãƒˆ
                "raw": {... ã¾ãŸã¯ æ–‡å­—åˆ— ...}  # å¾Œæ–¹äº’æ›ç”¨
                "route": "gpt",
                "pair": {"A": "gpt4o", "B": "hermes"},
            }
        """
        system_prompt = (
            "ã‚ãªãŸã¯ç‰©èªæ–‡ã®å¯©æŸ»å“¡ã§ã™ã€‚\n"
            "åŒã˜ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¯¾ã™ã‚‹ 2 ã¤ã®å¿œç­” A / B ã‚’æ¯”è¼ƒã—ã€"
            "ã©ã¡ã‚‰ãŒã‚ˆã‚Šå„ªã‚Œã¦ã„ã‚‹ã‹ã‚’åˆ¤å®šã—ã¦ãã ã•ã„ã€‚\n"
            "è©•ä¾¡è»¸ã®ä¾‹:\n"
            "  - æ–‡ä½“ã®è‡ªç„¶ã•\n"
            "  - æƒ…æ™¯æå†™ã®è±Šã‹ã•\n"
            "  - æ„Ÿæƒ…è¡¨ç¾ã®èª¬å¾—åŠ›\n"
            "  - ã“ã‚Œã¾ã§ã®æ–‡è„ˆã¨ã®æ•´åˆæ€§\n"
            "\n"
            "å¿…ãšæ¬¡ã® JSON å½¢å¼ã ã‘ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„:\n"
            "{\n"
            '  \"winner\": \"A\" ã¾ãŸã¯ \"B\",\n'
            '  \"score_diff\": 0.0ã€œ1.0 ã®æ•°å€¤,\n'
            '  \"comment\": \"æ—¥æœ¬èªã§ 1ã€œ3 æ–‡ã®ç†ç”±\"\n'
            "}\n"
        )

        user_content = (
            "ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€‘\n"
            f"{prompt}\n\n"
            "ã€å¿œç­”Aã€‘\n"
            f"{reply_a}\n\n"
            "ã€å¿œç­”Bã€‘\n"
            f"{reply_b}\n\n"
            "ä¸Šè¨˜ã‚’æ¯”è¼ƒã—ã€æŒ‡å®šã•ã‚ŒãŸ JSON å½¢å¼ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"
        )

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_content},
        ]

        text, meta = call_with_fallback(
            messages=messages,
            temperature=0.0,
            max_tokens=300,
        )

        # ã¾ãšã¯æœ€ä½é™ã®æ ã ã‘ç”¨æ„ã—ã¦ãŠã
        result: Dict[str, Any] = {
            "winner": None,
            "score_diff": 0.0,
            "comment": "",
            # ğŸ”¸ ç”Ÿãƒ†ã‚­ã‚¹ãƒˆã¯å¿…ãšä¿æŒ
            "raw_text": text,
            # ğŸ”¸ è§£æã«æˆåŠŸã—ãŸã‚‰ã“ã“ã« dict ã‚’å…¥ã‚Œã‚‹
            "raw_json": None,
            # ğŸ”¸ æ—¢å­˜ã‚³ãƒ¼ãƒ‰ã¨ã®äº’æ›ç”¨ï¼ˆå¾Œã§ raw_json or raw_text ã‚’è©°ã‚ã‚‹ï¼‰
            "raw": None,
            "route": meta.get("route"),
            "pair": {"A": label_a, "B": label_b},
        }

        parsed = self._safe_parse_json(text)

        if isinstance(parsed, dict):
            # ãƒ‘ãƒ¼ã‚¹ã«æˆåŠŸã—ãŸã‚‰ã€JSON ã®ä¸­èº«ã§ä¸Šæ›¸ã
            winner_raw = parsed.get("winner")
            if winner_raw == "A":
                result["winner"] = label_a
            elif winner_raw == "B":
                result["winner"] = label_b

            try:
                result["score_diff"] = float(parsed.get("score_diff", 0.0))
            except Exception:
                result["score_diff"] = 0.0

            comment = parsed.get("comment")
            if isinstance(comment, str):
                result["comment"] = comment.strip()

            # è§£ææ¸ˆã¿JSONã¯ã“ã“ã«
            result["raw_json"] = parsed
            # rawï¼ˆäº’æ›ç”¨ï¼‰ã«ã¯ JSON ã‚’å…¥ã‚Œã¦ãŠã
            result["raw"] = parsed
        else:
            # JSON ã¨ã—ã¦èª­ã‚ãªã‹ã£ãŸå ´åˆã¯ã€ç”Ÿãƒ†ã‚­ã‚¹ãƒˆã‚’ raw ã«å…¥ã‚Œã‚‹
            result["raw"] = text

        # winner ãŒæ±ºã¾ã‚‰ãªã‹ã£ãŸå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if result["winner"] is None:
            result["winner"] = label_a
            result["score_diff"] = 0.0
            if not result["comment"]:
                result["comment"] = (
                    "JSON ã®è§£æã«å¤±æ•—ã—ãŸãŸã‚ã€æš«å®šçš„ã« A å´ã‚’é¸æŠã—ã¾ã—ãŸã€‚"
                )

        return result

    def _safe_parse_json(self, text: str) -> Optional[Dict[str, Any]]:
        """
        LLM ã®å‡ºåŠ›ã‹ã‚‰ JSON ã‚‰ã—ãéƒ¨åˆ†ã‚’æŠœãå‡ºã—ã¦ãƒ‘ãƒ¼ã‚¹ã™ã‚‹ç°¡æ˜“ãƒ˜ãƒ«ãƒ‘ã€‚
        """
        try:
            stripped = text.strip()
            start = stripped.find("{")
            end = stripped.rfind("}")
            if start == -1 or end == -1 or end <= start:
                return None
            json_str = stripped[start : end + 1]
            return json.loads(json_str)
        except Exception:
            return None
