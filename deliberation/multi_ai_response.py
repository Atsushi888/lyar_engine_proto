from __future__ import annotations

from typing import Any, Dict
import streamlit as st

from components.multi_ai_display_config import MultiAIDisplayConfig
from components.multi_ai_model_viewer import MultiAIModelViewer
from components.multi_ai_judge_result_view import MultiAIJudgeResultView
from deliberation.judge_ai import JudgeAI

# ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§å¯©è­°å¯¾è±¡ã«ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ä¸€è¦§
PARTICIPATING_MODELS: Dict[str, str] = {
    "gpt4o": "GPT-4o",
    "hermes": "Hermes",
}


class MultiAIResponse:
    """
    ãƒãƒ«ãƒAIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚·ã‚¹ãƒ†ãƒ ã®ä¸­æ ¸ã‚¯ãƒ©ã‚¹ã€‚
    - models ã®è¡¨ç¤º
    - Judge ã®å®Ÿè¡Œã¨è¡¨ç¤º
    ã‚’ã¾ã¨ã‚ã¦æ‰±ã†ã€‚
    """

    def __init__(self) -> None:
        self.display_config = MultiAIDisplayConfig(initial=PARTICIPATING_MODELS)
        self.model_viewer = MultiAIModelViewer(self.display_config)
        self.judge_view = MultiAIJudgeResultView()
        self.judge_ai = JudgeAI()

    # ---- å†…éƒ¨ãƒ˜ãƒ«ãƒ‘ ----
    def _ensure_models(self, llm_meta: Dict[str, Any]) -> Dict[str, Any] | None:
        models = llm_meta.get("models")
        if isinstance(models, dict) and models:
            return models
        return None

    def _ensure_judge(self, llm_meta: Dict[str, Any]) -> Dict[str, Any] | None:
        judge = llm_meta.get("judge")
        if isinstance(judge, dict):
            return judge

        models = self._ensure_models(llm_meta)
        if not models or len(models) < 2:
            # 2 ãƒ¢ãƒ‡ãƒ«æœªæº€ãªã‚‰å¯©è­°ã—ãªã„
            return None

        # JudgeAI å´ã§ llm_meta["judge"] ã‚‚åŸ‹ã‚ã¦ãã‚Œã‚‹
        judge = self.judge_ai.run(llm_meta)
        return judge

    # ---- è¡¨ç¤ºã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ ----
    def render(self, llm_meta: Dict[str, Any] | None) -> None:
        st.markdown("#### âœï¸ ãƒãƒ«ãƒAIãƒ¬ã‚¹ãƒãƒ³ã‚¹")

        if not isinstance(llm_meta, dict) or not llm_meta:
            st.caption("ï¼ˆmodels æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“ï¼‰")
            return

        models = self._ensure_models(llm_meta)

        # ãƒ¢ãƒ‡ãƒ«å¿œç­”æ¯”è¼ƒ
        with st.expander("ğŸ’¬ ãƒ¢ãƒ‡ãƒ«å¿œç­”æ¯”è¼ƒ", expanded=True):
            if isinstance(models, dict) and models:
                # æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ãŒæ¥ãŸã‚‰è‡ªå‹•ã§ DisplayConfig ã«ç™»éŒ²
                self.display_config.ensure_from_models(models)
                self.model_viewer.render(models)
            else:
                st.caption("ï¼ˆmodels æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“ï¼‰")

        # å¯©è­°çµæœ
        with st.expander("âš–ï¸ ãƒãƒ«ãƒAIå¯©è­°çµæœ", expanded=True):
            judge = self._ensure_judge(llm_meta)
            self.judge_view.render(judge)
